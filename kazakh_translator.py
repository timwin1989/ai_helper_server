from search_and_respond import query_openai


def is_probably_kazakh(text: str) -> bool:
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ —Ç–µ–∫—Å—Ç –∫–∞–∑–∞—Ö—Å–∫–∏–µ —Å–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏–µ –±—É–∫–≤—ã.
    """
    kazakh_chars = "”ô“ì“õ“£”©“±“Ø“ª—ñ"
    return any(char in text.lower() for char in kazakh_chars)

def translate_kazakh_to_russian(text: str) -> str:
    """
    –ü–µ—Ä–µ–≤–æ–¥ —Ç–µ–∫—Å—Ç–∞ —Å –∫–∞–∑–∞—Ö—Å–∫–æ–≥–æ –Ω–∞ —Ä—É—Å—Å–∫–∏–π —Å –ø–æ–º–æ—â—å—é GPT (OpenAI API).
    –ï—Å–ª–∏ —Ç–µ–∫—Å—Ç –Ω–µ –Ω–∞ –∫–∞–∑–∞—Ö—Å–∫–æ–º ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –µ–≥–æ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π.
    """
    text = text.strip()
    if not text or len(text) < 5:
        return text

    if not is_probably_kazakh(text):
        print("‚è≠Ô∏è –¢–µ–∫—Å—Ç –Ω–µ –ø–æ—Ö–æ–∂ –Ω–∞ –∫–∞–∑–∞—Ö—Å–∫–∏–π, –ø–µ—Ä–µ–≤–æ–¥ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è.")
        return text

    system_prompt = "–¢—ã –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥—á–∏–∫. –ü–µ—Ä–µ–≤–æ–¥–∏ —Ç–µ–∫—Å—Ç —Å –∫–∞–∑–∞—Ö—Å–∫–æ–≥–æ –Ω–∞ —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫ —Ç–æ—á–Ω–æ –∏ –≥—Ä–∞–º–æ—Ç–Ω–æ, –±–µ–∑ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –ª–∏—à–Ω–µ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏."
    prompt = f"–ü–µ—Ä–µ–≤–µ–¥–∏ —Å–ª–µ–¥—É—é—â–∏–π —Ç–µ–∫—Å—Ç —Å –∫–∞–∑–∞—Ö—Å–∫–æ–≥–æ –Ω–∞ —Ä—É—Å—Å–∫–∏–π:\n\n{text}"
    print("üîÅ –ü–µ—Ä–µ–≤–æ–¥ –≤—ã–ø–æ–ª–Ω–µ–Ω.")
    translated_text = query_openai(system_prompt, prompt, temperature=0)
    return translated_text


# from transformers import AutoModelForSeq2SeqLM, AutoTokenizer
# import torch
# import re

# # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞
# device = 'cuda' if torch.cuda.is_available() else 'cpu'

# # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞ –æ–¥–∏–Ω —Ä–∞–∑ –ø—Ä–∏ –∏–º–ø–æ—Ä—Ç–µ –º–æ–¥—É–ª—è
# model_name = 'deepvk/kazRush-kk-ru'
# model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device)
# tokenizer = AutoTokenizer.from_pretrained(model_name)

# def split_sentences(text: str) -> list[str]:
#     """
#     –ü—Ä–æ—Å—Ç–∞—è —Ä–∞–∑–±–∏–≤–∫–∞ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è.
#     """
#     # –ó–∞–º–µ–Ω—è–µ–º ! ? –Ω–∞ . –∏ —Ä–∞–∑–±–∏–≤–∞–µ–º –ø–æ —Ç–æ—á–∫–µ
#     text = re.sub(r'[!?]', '.', text)
#     return [s.strip() for s in text.split('.') if s.strip()]

# def translate_kazakh_to_russian(text: str) -> str:
#     """
#     –ü–µ—Ä–µ–≤–æ–¥ —Ç–µ–∫—Å—Ç–∞ —Å –∫–∞–∑–∞—Ö—Å–∫–æ–≥–æ –Ω–∞ —Ä—É—Å—Å–∫–∏–π –ø–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º (–±–µ–∑ nltk).
#     """
#     if not text or len(text.strip()) < 5:
#         return text

#     sentences = split_sentences(text)
#     translated_sentences = []

#     for sentence in sentences:
#         try:
#             inputs = tokenizer(sentence, return_tensors='pt', truncation=True, max_length=512).to(device)
#             with torch.no_grad():
#                 outputs = model.generate(
#                     **inputs,
#                     num_beams=5,
#                     max_new_tokens=128,
#                     no_repeat_ngram_size=3,
#                     early_stopping=True
#                 )
#             translated = tokenizer.decode(outputs[0], skip_special_tokens=True)
#             translated_sentences.append(translated)
#         except Exception as e:
#             print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –≤ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–∏:\n{sentence}\n{e}")
#             translated_sentences.append(sentence)

#     return " ".join(translated_sentences)

# if __name__ == "__main__":
#     sample_text = "“ö–∞–∑–∞“õ—Å—Ç–∞–Ω ‚Äî –®—ã“ì—ã—Å –ï—É—Ä–æ–ø–∞ –º–µ–Ω –û—Ä—Ç–∞–ª—ã“õ –ê–∑–∏—è–¥–∞ –æ—Ä–Ω–∞–ª–∞—Å“õ–∞–Ω –º–µ–º–ª–µ–∫–µ—Ç. –û–ª –±–∞–π —Ç–∞–±–∏“ì–∏ —Ä–µ—Å—É—Ä—Å—Ç–∞—Ä“ì–∞ –∏–µ."
#     translated = translate_kazakh_to_russian(sample_text)
#     print("‚û° –ü–µ—Ä–µ–≤–æ–¥:", translated)
