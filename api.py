from fastapi import FastAPI, Form, UploadFile, File, Form
from fastapi.responses import JSONResponse
from typing import Optional
from pydantic import BaseModel
import requests as httpx
import tempfile
from pathlib import Path
from docx import Document  # –î–ª—è .docx
import uuid
import re
import subprocess
from search_and_respond import extract_text_from_pdf, query_openai, search_by_title_summary, generate_answer
from utils import save_html_to_pdf, save_to_docx
from fastapi.staticfiles import StaticFiles
from fastapi.middleware.cors import CORSMiddleware
from uuid import uuid4
from bs4 import BeautifulSoup
from kazakh_translator import translate_kazakh_to_russian

app = FastAPI()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000"],  # –∏–ª–∏ ["*"] –¥–ª—è –≤—Å–µ—Ö
    allow_credentials=True,
    allow_methods=["*"],  # –∏–ª–∏ ['POST']
    allow_headers=["*"],
)
# –†–∞–∑–¥–∞—á–∞ PDF-—Ñ–∞–π–ª–æ–≤ –∏–∑ –ø–∞–ø–∫–∏ "answers"
app.mount("/answers", StaticFiles(directory="answers"), name="answers")
app.mount("/pdfs", StaticFiles(directory="pdfs"), name="pdfs")


# def force_translate_to_russian(text: str) -> str:
#     paragraphs = [p for p in text.split("\n") if len(p.strip()) > 5]
#     translated_paragraphs = []
#     for paragraph in paragraphs:
#         try:
#             translated =  translate_kazakh_to_russian(paragraph)
#             translated_paragraphs.append(translated)
#         except Exception as e:
#             print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–µ—Ä–µ–≤–æ–¥–µ –∞–±–∑–∞—Ü–∞: {e}")
#             translated_paragraphs.append(paragraph)
#     return "\n\n".join(translated_paragraphs)

    
def extract_source_and_clean_text(text: str):
    text = text.lstrip()

    match = re.search(r'\[–ò—Å—Ç–æ—á–Ω–∏–∫:\s*"?([^"\]]+)"?\]', text)
    if match:
        source = match.group(1).strip()
        cleaned_text = text[:match.start()] + text[match.end():]
        if source.lower() == "–±–µ–∑ –∏—Å—Ç–æ—á–Ω–∏–∫–∞":
            return None, cleaned_text
        return source, cleaned_text

    return None, text

def clean_html_code_block(text: str) -> str:
    # –£–¥–∞–ª—è–µ–º –±–ª–æ–∫–∏ —Å ```html ... ```
    text = re.sub(r"```html\s*([\s\S]*?)\s*```", r"\1", text, flags=re.IGNORECASE)
    # –£–¥–∞–ª—è–µ–º –ø—Ä–æ—Å—Ç–æ ``` ... ```
    text = re.sub(r"```\s*([\s\S]*?)\s*```", r"\1", text)
    return text.strip()

# üßæ JSON-—Å—Ö–µ–º–∞
class SummarizeRequestParams(BaseModel):
    url: str
    lang: str
    
    
class UrlRequest(BaseModel):
    url: str
    short_context: str
    lang: str

# === API endpoint –¥–ª—è —Ä–µ–∑—é–º–∏—Ä–æ–≤–∞–Ω–∏—è –∑–∞–ø—Ä–æ—Å–∞ –ø–æ URL ===
@app.post("/summarize-request")
async def summarize_request(data: SummarizeRequestParams):
    file_url = data.url
    lang = data.lang
    system_promps = f"""–¢—ã ‚Äî –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫. –°–¥–µ–ª–∞–π –∫—Ä–∞—Ç–∫–æ–µ, –¥–µ–ª–æ–≤–æ–µ —Ä–µ–∑—é–º–µ –∑–∞–ø—Ä–æ—Å–∞.
        –û—Ç–≤–µ—Ç –ø–µ—Ä–µ–≤–µ–¥–∏ –Ω–∞: '{lang}'.
        –°—Ñ–æ—Ä–º–∏—Ä—É–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ –≤–∏–¥–µ HTML —Å –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π —Ä–∞–∑–º–µ—Ç–∫–æ–π: 
        –∏—Å–ø–æ–ª—å–∑—É–π <p> –¥–ª—è –∞–±–∑–∞—Ü–µ–≤, —Å–æ—Ö—Ä–∞–Ω—è–π –ª–æ–≥–∏—á–µ—Å–∫–∏–µ –æ—Ç—Å—Ç—É–ø—ã –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ç–µ–∫—Å—Ç–∞.
        –í–∞–∂–Ω–æ –Ω–µ –¥–æ–±–∞–≤–ª—è–π –ø–æ—è—Å–Ω–µ–Ω–∏–π –Ω–µ –≤ –Ω–∞—á–∞–ª–µ –Ω–µ –≤ –∫–æ–Ω—Ü–µ –Ω–∏ –∫–∞–∫–∏—Ö! —Ç–∏–ø–∞: ```html
    """

    try:
        response = httpx.get(file_url, verify=False)
        if response.status_code != 200:
            return {"error": "–ù–µ —É–¥–∞–ª–æ—Å—å —Å–∫–∞—á–∞—Ç—å PDF"}

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º PDF –≤—Ä–µ–º–µ–Ω–Ω–æ
        uid = uuid.uuid4().hex
        temp_path = Path(f"temp/request_{uid}.pdf")
        temp_path.parent.mkdir(exist_ok=True)
        with open(temp_path, "wb") as f:
            f.write(response.content)

        request_text = extract_text_from_pdf(str(temp_path))
        if not request_text.strip():
            return JSONResponse(
                content={"error": "PDF-—Ñ–∞–π–ª –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–µ–∫—Å—Ç. –í–æ–∑–º–æ–∂–Ω–æ, –æ–Ω —Å–æ—Å—Ç–æ–∏—Ç —Ç–æ–ª—å–∫–æ –∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π."},
                status_code=400
            )
        summary = query_openai(system_promps, request_text+f"""–û—Ç–≤–µ—Ç –ø–µ—Ä–µ–≤–µ–¥–∏ –Ω–∞ —è–∑—ã–∫: {lang}""")
        # if USE_OLLAMA:
        #     summary = summarize_with_ollama(translated_text)
        # else:
        #     summary = summarize_with_openai(translated_text, lang)

        return {"summary": clean_html_code_block(summary)}
    except Exception as e:
        return {"error": str(e)}

def extract_doc_text(doc_path: str) -> str:
    result = subprocess.run(["antiword", doc_path], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    if result.returncode == 0:
        return result.stdout.decode("utf-8")
    else:
        raise RuntimeError(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ —Ç–µ–∫—Å—Ç–∞: {result.stderr.decode()}")
    
@app.post("/generate-request/")
async def generate_by_upload(
    file: Optional[UploadFile] = File(None),
    short_context: str = Form(...),
    lang: str = Form(...),
    content_text: Optional[str] = Form(None)
):
    try:
        uid = uuid.uuid4().hex
        request_text = ""

        # === 1. –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞, –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å ===
        if file:
            ext = file.filename.split('.')[-1].lower()
            temp_dir = Path("requests")
            temp_dir.mkdir(exist_ok=True)
            temp_path = temp_dir / f"request_{uid}.{ext}"

            with open(temp_path, "wb") as f:
                f.write(await file.read())

            if ext == "pdf":
                request_text = extract_text_from_pdf(str(temp_path))
                if not request_text.strip():
                    return JSONResponse(
                        content={"error": "PDF-—Ñ–∞–π–ª –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–µ–∫—Å—Ç. –í–æ–∑–º–æ–∂–Ω–æ, –æ–Ω —Å–æ—Å—Ç–æ–∏—Ç —Ç–æ–ª—å–∫–æ –∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π."},
                        status_code=400
                    )
            elif ext == "docx":
                doc = Document(str(temp_path))
                request_text = "\n".join([para.text for para in doc.paragraphs])
                if not request_text.strip():
                    return JSONResponse(
                        content={"error": "docx-—Ñ–∞–π–ª –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–µ–∫—Å—Ç. –í–æ–∑–º–æ–∂–Ω–æ, –æ–Ω —Å–æ—Å—Ç–æ–∏—Ç —Ç–æ–ª—å–∫–æ –∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π."},
                        status_code=400
                    )
            elif ext == "doc":
                request_text = extract_doc_text(str(temp_path))
                if not request_text.strip():
                    return JSONResponse(
                        content={"error": "doc-—Ñ–∞–π–ª –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–µ–∫—Å—Ç. –í–æ–∑–º–æ–∂–Ω–æ, –æ–Ω —Å–æ—Å—Ç–æ–∏—Ç —Ç–æ–ª—å–∫–æ –∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π."},
                        status_code=400
                    )
            else:
                return JSONResponse(content={"error": f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç: .{ext}"}, status_code=400)

        # === 2. –ï—Å–ª–∏ —Ñ–∞–π–ª–∞ –Ω–µ—Ç, –±–µ—Ä—ë–º content_text ===
        elif content_text:
            request_text = content_text
        else:
            return JSONResponse(
                content={"error": "–ù–µ–æ–±—Ö–æ–¥–∏–º–æ –ø—Ä–∏–∫—Ä–µ–ø–∏—Ç—å —Ñ–∞–π–ª –∏–ª–∏ –ø–µ—Ä–µ–¥–∞—Ç—å —Ç–µ–∫—Å—Ç"},
                status_code=400
            )

        # === –ü–µ—Ä–µ–≤–æ–¥ —Ç–µ–∫—Å—Ç–∞ ===
        translated_request_text = translate_kazakh_to_russian(request_text)

        # === –ü–æ–∏—Å–∫ –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è ===
        results = search_by_title_summary(short_context)
        similar_docs = [
            {
                "text": r["text"],
                "context_text": r.get("context_text", r["text"]),
                "source": r.get("source", "–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ñ–∞–π–ª")
            }
            for r in results
        ]

        system_prompt = f"""–¢—ã ‚Äî –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫ –¥–µ–ø—É—Ç–∞—Ç–∞ –ú–∞–∂–∏–ª–∏—Å–∞ –ü–∞—Ä–ª–∞–º–µ–Ω—Ç–∞ –†–µ—Å–ø—É–±–ª–∏–∫–∏ –ö–∞–∑–∞—Ö—Å—Ç–∞–Ω.
        –¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –ø–æ–º–æ—á—å —Å—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π –¥–µ–ø—É—Ç–∞—Ç—Å–∫–∏–π –∑–∞–ø—Ä–æ—Å –Ω–∞ –æ—Å–Ω–æ–≤–∞–Ω–∏–∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö.

        –ò—Å–ø–æ–ª—å–∑—É–π –¥–µ–ª–æ–≤–æ–π, –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π —Å—Ç–∏–ª—å. –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä—É–π —Ç–µ–∫—Å—Ç –ª–æ–≥–∏—á–Ω–æ: –≤–≤–µ–¥–µ–Ω–∏–µ, —Å—É—Ç—å –æ–±—Ä–∞—â–µ–Ω–∏—è, –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã –∏–ª–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è.

        –ï—Å–ª–∏ —É–∫–∞–∑–∞–Ω—ã —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤), –∏—Å–ø–æ–ª—å–∑—É–π –∏—Ö –∫–∞–∫ –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ –∏–ª–∏ —Å—Å—ã–ª–∫—É. –í –Ω–∞—á–∞–ª–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ —É–∫–∞–∂–∏ –∏—Å—Ç–æ—á–Ω–∏–∫: 
        –µ—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω —Ñ—Ä–∞–≥–º–µ–Ω—Ç, –Ω–∞–ø–∏—à–∏ [–ò—Å—Ç–æ—á–Ω–∏–∫: "–∏–º—è_—Ñ–∞–π–ª–∞.pdf"], –µ—Å–ª–∏ –Ω–µ—Ç ‚Äî –Ω–∞–ø–∏—à–∏ [–ò—Å—Ç–æ—á–Ω–∏–∫: "–±–µ–∑ –∏—Å—Ç–æ—á–Ω–∏–∫–∞"].

        –û—Ç–≤–µ—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –Ω–∞ —è–∑—ã–∫–µ: {lang}.

        –°—Ñ–æ—Ä–º–∏—Ä—É–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ –≤–∏–¥–µ HTML —Å –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π —Ä–∞–∑–º–µ—Ç–∫–æ–π:
        ‚Äî –∏—Å–ø–æ–ª—å–∑—É–π <p> –¥–ª—è –∞–±–∑–∞—Ü–µ–≤;
        ‚Äî –Ω–µ –¥–æ–±–∞–≤–ª—è–π –Ω–∏–∫–∞–∫–∏—Ö –ø–æ—è—Å–Ω–µ–Ω–∏–π;
        ‚Äî –Ω–µ –ø–∏—à–∏ –Ω–∏—á–µ–≥–æ –∫—Ä–æ–º–µ —Å–∞–º–æ–≥–æ HTML-–∫–æ–Ω—Ç–µ–Ω—Ç–∞;
        ‚Äî —Å–æ—Ö—Ä–∞–Ω—è–π –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ç–µ–∫—Å—Ç–∞: –æ–±—Ä–∞—â–µ–Ω–∏–µ, —Å—É—Ç—å –ø—Ä–æ–±–ª–µ–º—ã, –æ–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ, —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∞ –∑–∞–ø—Ä–æ—Å–∞.
        """
        # print(translated_request_text)
        
        # –ø—Ä–æ—Å–º–æ—Ç—Ä–µ—Ç—å —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –∏–Ω–¥–µ–∫—Å–∞
        # with open("faiss_index/meta.json", "r", encoding="utf-8") as f:
        #     meta = json.load(f)

        # for i, item in enumerate(meta[:10]):  # –ø–æ–∫–∞–∂–µ–º –ø–µ—Ä–≤—ã–µ 10
        #     print(f"üîπ [{i}] context_text: {item.get('context_text', '')[:100]}")

        ai_response = generate_answer(translated_request_text, similar_docs, system_prompt, lang, use_openai=True)

        # === –°–æ—Ö—Ä–∞–Ω—è–µ–º PDF ===
        Path("answers").mkdir(exist_ok=True)
        pdf_file = f"{uid}_answer.pdf"
        source, cleaned = extract_source_and_clean_text(ai_response["ai_answer"])
        save_html_to_pdf(cleaned, pdf_file)

        return {
            "fragments_list": ai_response["fragments_list"],
            "text": clean_html_code_block(cleaned),
            "pdf_url": f"/answers/{pdf_file}",
            "file_contenxt_source": source
        }

    except Exception as e:
        return JSONResponse(content={"error": str(e)}, status_code=500)

# @app.post("/generate-by-url/")
# async def generate_by_url(payload: UrlRequest):
#     file_url = payload.url
#     short_context = payload.short_context
#     lang = payload.lang 

#     print("short_context: "+short_context)
#     try:
#         # –ó–∞–≥—Ä—É–∂–∞–µ–º PDF
#         response = httpx.get(file_url, verify=False)
#         if response.status_code != 200:
#             return {"error": "–ù–µ —É–¥–∞–ª–æ—Å—å —Å–∫–∞—á–∞—Ç—å PDF"}

#         # –£–Ω–∏–∫–∞–ª—å–Ω–æ–µ –∏–º—è
#         uid = uuid.uuid4().hex
#         request_path = Path(f"requests/request_{uid}.pdf")
#         request_path.parent.mkdir(exist_ok=True)

#         with open(request_path, "wb") as f:
#             f.write(response.content)

#         # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –∏ –∏—â–µ–º –ø–æ—Ö–æ–∂–∏–µ
#         request_text = extract_text_from_pdf(str(request_path))
#         translated_request_text = translate_kazakh_to_russian(short_context+": " + request_text)
 
#         # –ù–∞—Ö–æ–¥–∏–º –ø–æ—Ö–æ–∂–∏–µ –ø–æ –ø–µ—Ä–µ–≤–æ–¥—É
#         results = search(translated_request_text, short_context)
#         similar_docs = [{"text": r["text"], "source": r.get("source", "–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ñ–∞–π–ª")} for r in results]

#         system_prompt = f"""–¢—ã ‚Äî –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫ –ü—Ä–∞–≤–∏—Ç–µ–ª—å—Å—Ç–≤–∞ –†–µ—Å–ø—É–±–ª–∏–∫–∏ –ö–∞–∑–∞—Ö—Å—Ç–∞–Ω.
#             –û—Ç–≤–µ—á–∞–π —Å—Ç—Ä–æ–≥–æ, –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–º –¥–µ–ª–æ–≤—ã–º —è–∑—ã–∫–æ–º. –û—Ç–≤–µ—Ç –ø–µ—Ä–µ–≤–µ–¥–∏ –Ω–∞ —è–∑—ã–∫: {lang}.
#             —á—Ç–æ–±—ã —Å–æ—Å—Ç–∞–≤–∏—Ç—å –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç –æ—Ç –∏–º–µ–Ω–∏, –∫ –∫–æ—Ç–æ—Ä–æ–º—É –æ–±—Ä–∞—â–∞—é—Ç—Å—è –≤ –∑–∞–ø—Ä–æ—Å–µ.
#             –°—Ñ–æ—Ä–º–∏—Ä—É–π —Ç–æ—á–Ω—ã–π, —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç. –ò—Å–ø–æ–ª—å–∑—É–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤.
#             –°—Ñ–æ—Ä–º–∏—Ä—É–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ –≤–∏–¥–µ HTML —Å –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π —Ä–∞–∑–º–µ—Ç–∫–æ–π: 
#             –∏—Å–ø–æ–ª—å–∑—É–π <p> –¥–ª—è –∞–±–∑–∞—Ü–µ–≤, —Å–æ—Ö—Ä–∞–Ω—è–π –ª–æ–≥–∏—á–µ—Å–∫–∏–µ –æ—Ç—Å—Ç—É–ø—ã –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ç–µ–∫—Å—Ç–∞.
#             –ù–µ –¥–æ–±–∞–≤–ª—è–π –ø–æ—è—Å–Ω–µ–Ω–∏–π. –ù–µ –¥–æ–±–∞–≤–ª—è–π –Ω–∏—á–µ–≥–æ –∫—Ä–æ–º–µ HTML-—Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ –æ—Ç–≤–µ—Ç–∞.
#             –í –Ω–∞—á–∞–ª–µ –æ—Ç–≤–µ—Ç–∞ —É–∫–∞–∂–∏ –∏—Å—Ç–æ—á–Ω–∏–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–≥–æ —Ñ—Ä–∞–≥–º–µ–Ω—Ç–∞ –µ—Å–ª–∏ –∫–∞–∫–æ–π —Ç–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª, –µ—Å–ª–∏ –Ω–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª —Ç–æ –ø–∏—à–∏ —á—Ç–æ –±–µ–∑ –∏—Å—Ç–æ—á–Ω–∏–∫–∞, –ø—Ä–∏–º–µ—Ä: –µ—Å–ª–∏ –µ—Å—Ç—å: [–ò—Å—Ç–æ—á–Ω–∏–∫: "8863_10026.pdf"] –µ—Å–ª–∏ –Ω–µ—Ç: [–ò—Å—Ç–æ—á–Ω–∏–∫: "–±–µ–∑ –∏—Å—Ç–æ—á–Ω–∏–∫–∞"]
#         """
#         # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
#         ai_response = generate_answer(translated_request_text, similar_docs, system_prompt, lang, use_openai=True)

#         # –°–æ—Ö—Ä–∞–Ω—è–µ–º
#         Path("answers").mkdir(exist_ok=True)
#         pdf_file = f"{uid}_answer.pdf"
#         #print("DEBUG: ai_answer type =", type(ai_response["ai_answer"]))
#         source, cleaned = extract_source_and_clean_text(ai_response["ai_answer"])
#         save_html_to_pdf(cleaned, pdf_file)

#         return {
#             "fragments_list": ai_response["fragments_list"],
#             "text": clean_html_code_block(cleaned),
#             "pdf_url": f"/answers/{pdf_file}",
#             "file_contenxt_source": source
#         }

#     except Exception as e:
#         return {"error": str(e)}
    
# üìÑ HTML ‚Üí PDF
@app.post("/generate-pdf-from-html/")
async def generate_pdf_from_html(html: str = Form(...)):
    filename = f"{uuid4().hex}_from_html.pdf"
    save_html_to_pdf(html, filename)
    return {
        "message": "‚úÖ PDF —Å–æ–∑–¥–∞–Ω –∏–∑ HTML",
        "pdf_url": f"/answers/{filename}"
    }
@app.post("/generate-docx-from-html/")
async def generate_docx_from_html(html: str = Form(...)):
    filename = f"{uuid4().hex}_from_html.docx"
    save_to_docx(html, filename)
    return {
        "message": "‚úÖ DOCX —Å–æ–∑–¥–∞–Ω –∏–∑ HTML",
        "docx_url": f"/answers/{filename}"
    }

@app.post("/translate-html/")
async def translate_html(html: str = Form(...), target_lang: str = Form(...)):
    try:
        # –†–∞–∑–±–æ—Ä HTML
        soup = BeautifulSoup(html, "html.parser")
        # –°—Ñ–æ—Ä–º–∏—Ä—É–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ –≤–∏–¥–µ HTML —Å –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π —Ä–∞–∑–º–µ—Ç–∫–æ–π, 
        # –∏—Å–ø–æ–ª—å–∑—É–π <p> –¥–ª—è –∞–±–∑–∞—Ü–µ–≤, —Å–æ—Ö—Ä–∞–Ω—è–π –ª–æ–≥–∏—á–µ—Å–∫–∏–µ –æ—Ç—Å—Ç—É–ø—ã –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ç–µ–∫—Å—Ç–∞.

        # –ü–µ—Ä–µ–≤–æ–¥ –∫–∞–∂–¥–æ–≥–æ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞
        for tag in soup.find_all(string=True):
            original_text = tag.strip()
            if original_text:
                system_promps = "–¢—ã –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥—á–∏–∫"
                prompt = f"""
                    –ü–µ—Ä–µ–≤–µ–¥–∏ —Å–ª–µ–¥—É—é—â–∏–π —Ç–µ–∫—Å—Ç –Ω–∞ {target_lang}.

                    –°–æ—Ö—Ä–∞–Ω–∏ —Å—Ç–∏–ª—å, –Ω–æ –Ω–µ –¥–æ–±–∞–≤–ª—è–π –ø–æ—è—Å–Ω–µ–Ω–∏–π, —Ç–æ–ª—å–∫–æ –ø–µ—Ä–µ–≤–æ–¥
                    {original_text}
                """
                translated = query_openai(system_promps, prompt)
                tag.replace_with(translated)

        return {
            "message": f"‚úÖ –ü–µ—Ä–µ–≤–æ–¥ –≤—ã–ø–æ–ª–Ω–µ–Ω –Ω–∞ {target_lang}",
            "translated_html": clean_html_code_block(str(soup))
        }

    except Exception as e:
        return {"error": str(e)}